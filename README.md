# text-generator
generator uses a n-gram language model
Генератор использует 1-граммную языковую модель на русском языке. Модель уже обучена на произведениях Замятина "Мы" и Шолохова "Тихий Дон".
В проекте реализован консольный интерфейс через argparse. 
При вводе текстов для тренировыке модели программа автоматически считывает символы согласно utf-8, остальные символы игнорируются.(для этого используется встроенная библиотека codecs)

Параметры train.py:
--input-dir - путь к директории, в которой лежит коллекция документов. Если данный аргумент не задан, считать, что тексты вводятся из stdin.
--model - путь к файлу, в который сохраняется модель.

Параметры generate.py:
--model - путь к файлу, из которого загружается модель.
--prefix - необязательный аргумент. Начало предложения (одно или несколько слов). Если не указано, выбираем начальное слово случайно из всех слов.
--length - длина генерируемой последовательности.
